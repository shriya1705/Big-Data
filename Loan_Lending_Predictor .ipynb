{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/FileStore/tables/train_Loan.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing nulls in Loan amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import mean, md5\n",
    "mean_val= df.select(mean(df['LoanAmount'])).collect()\n",
    "mean_la=mean_val[0][0]\n",
    "df=df.na.fill(mean_la,subset=['LoanAmount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing nulls in Loan amount term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_counts = df.groupBy(['Loan_Amount_Term']).count().alias('counts')\n",
    "LA_counts.sort(col(\"count\").desc()).show()\n",
    "LA_mode=LA_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "print(LA_mode)\n",
    "temp_LA = LA_counts.filter(LA_counts['count']==LA_mode)\n",
    "temp_LA.printSchema()\n",
    "LA_mode = temp_LA.select(['Loan_Amount_Term']).collect()[0][0]\n",
    "df=df.na.fill(LA_mode,subset=['Loan_Amount_Term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing nulls in gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Gender_counts = df.groupBy(['Gender']).count().alias('counts')\n",
    "Gender_counts.sort(col(\"count\").desc()).show()\n",
    "Gender_mode=Gender_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_Gender = Gender_counts.filter(Gender_counts['count']==Gender_mode)\n",
    "Gender_mode = temp_Gender.select(['Gender']).collect()[0][0]\n",
    "df=df.na.fill(Gender_mode,subset=['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing null in married by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Mar_counts = df.groupBy(['Married']).count().alias('counts')\n",
    "Mar_counts.sort(col(\"count\").desc()).show()\n",
    "Mar_mode=Mar_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_mar = Mar_counts.filter(Mar_counts['count']==Mar_mode)\n",
    "Mar_mode = temp_mar.select(['Married']).collect()[0][0]\n",
    "df=df.na.fill(Mar_mode,subset=['Married'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing null in dependents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dep_counts = df.groupBy(['Dependents']).count().alias('counts')\n",
    "Dep_counts.sort(col(\"count\").desc()).show()\n",
    "Dep_mode=Dep_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_dep = Dep_counts.filter(Dep_counts['count']==Dep_mode)\n",
    "Dep_mode = temp_dep.select(['Dependents']).collect()[0][0]\n",
    "df=df.na.fill(Dep_mode,subset=['Dependents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing null in self employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emp_counts = df.groupBy(['Self_Employed']).count().alias('counts')\n",
    "emp_counts.sort(col(\"count\").desc()).show()\n",
    "emp_mode=emp_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_emp = emp_counts.filter(emp_counts['count']==emp_mode)\n",
    "emp_mode = temp_emp.select(['Self_Employed']).collect()[0][0]\n",
    "df=df.na.fill(emp_mode,subset=['Self_Employed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing null in credit history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ch_counts = df.groupBy(['Credit_History']).count().alias('counts')\n",
    "ch_counts.sort(col(\"count\").desc()).show()\n",
    "ch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\n",
    "ch_mode = temp_ch.select(['Credit_History']).collect()[0][0]\n",
    "df=df.na.fill(ch_mode,subset=['Credit_History'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new feature total income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_totalincome = df.withColumn('total_income', df['ApplicantIncome']+df['CoapplicantIncome'])\n",
    "df_with_totalincome.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new feature ratio of total income to loan amount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_ratio = df_with_totalincome.withColumn('ratio', df_with_totalincome['total_income']/df_with_totalincome['LoanAmount'])\n",
    "df_with_ratio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_data = df_with_ratio.select('Gender',\n",
    " 'Married',\n",
    " 'Dependents',\n",
    " 'Education',\n",
    " 'Self_Employed',\n",
    " 'ApplicantIncome',\n",
    " 'CoapplicantIncome',\n",
    " 'LoanAmount',\n",
    " 'Loan_Amount_Term',\n",
    " 'Credit_History',\n",
    " 'Property_Area',\n",
    " 'Loan_Status','total_income','ratio')\n",
    "selected_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = selected_data.where(selected_data.Gender.isNotNull())\n",
    "final = final.where(final.Married.isNotNull())\n",
    "final = final.where(final.Dependents.isNotNull())\n",
    "final = final.where(final.Education.isNotNull())\n",
    "final = final.where(final.Self_Employed.isNotNull())\n",
    "final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy coding gender Male =0 ; Female =1\n",
    "gen_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"_Gender_index\" )\n",
    "gen_model = gen_indexer.fit(final)\n",
    "gen_indexed = gen_model.transform(final)\n",
    "gen_encoder = OneHotEncoder( inputCol=\"_Gender_index\", outputCol=\"_Gender_vec\")\n",
    "final1 = gen_encoder.transform(gen_indexed)\n",
    "final1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Married Yes =0, No =1\n",
    "mar_indexer = StringIndexer(inputCol=\"Married\", outputCol=\"_Married_index\" )\n",
    "mar_model = mar_indexer.fit(final1)\n",
    "mar_indexed = mar_model.transform(final1)\n",
    "mar_encoder = OneHotEncoder( inputCol=\"_Married_index\", outputCol=\"_Married_vec\")\n",
    "final2 = mar_encoder.transform(mar_indexed)\n",
    "final2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Dependent\n",
    "dep_indexer = StringIndexer(inputCol=\"Dependents\", outputCol=\"_Dependents_index\" )\n",
    "dep_model = dep_indexer.fit(final2)\n",
    "dep_indexed = dep_model.transform(final2)\n",
    "dep_encoder = OneHotEncoder( inputCol=\"_Dependents_index\", outputCol=\"_Dependents_vec\")\n",
    "final3 = dep_encoder.transform(dep_indexed)\n",
    "final3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Education graduate =0 ; not graduate =1\n",
    "edu_indexer = StringIndexer(inputCol=\"Education\", outputCol=\"_Education_index\" )\n",
    "edu_model = edu_indexer.fit(final3)\n",
    "edu_indexed = edu_model.transform(final3)\n",
    "edu_encoder = OneHotEncoder( inputCol=\"_Education_index\", outputCol=\"_Education_vec\")\n",
    "final4 = edu_encoder.transform(edu_indexed)\n",
    "final4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Self employed No =0 ; Yes= 1\n",
    "emp_indexer = StringIndexer(inputCol=\"Self_Employed\", outputCol=\"_Self_Employed_index\" )\n",
    "emp_model = emp_indexer.fit(final4)\n",
    "emp_indexed = emp_model.transform(final4)\n",
    "emp_encoder = OneHotEncoder( inputCol=\"_Self_Employed_index\", outputCol=\"_Self_Employed_vec\")\n",
    "final5 = emp_encoder.transform(emp_indexed)\n",
    "final5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Property Area Urban =1; Rural =0;semiurban =2\n",
    "area_indexer = StringIndexer(inputCol=\"Property_Area\", outputCol=\"_Property_Area_index\" )\n",
    "area_model = area_indexer.fit(final5)\n",
    "area_indexed = area_model.transform(final5)\n",
    "area_encoder = OneHotEncoder( inputCol=\"_Property_Area_index\", outputCol=\"_Property_Area_vec\")\n",
    "final6 = area_encoder.transform(area_indexed)\n",
    "final6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy coding Loan Status yes =0 ; No = 1\n",
    "loan_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"_Loan_Status_index\" )\n",
    "loan_model = loan_indexer.fit(final6)\n",
    "loan_indexed = loan_model.transform(final6)\n",
    "loan_encoder = OneHotEncoder( inputCol=\"_Loan_Status_index\", outputCol=\"_Loan_Status_vec\")\n",
    "final7 = loan_encoder.transform(loan_indexed)\n",
    "final7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','total_income','ratio',\n",
    " '_Gender_vec', \n",
    " '_Married_vec', \n",
    " '_Dependents_vec','_Education_vec','_Self_Employed_vec','_Property_Area_vec'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final8 = assembler.transform(final7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final= final8.select(\"features\",\"_Loan_Status_index\")\n",
    "new_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = new_final.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = '_Loan_Status_index', maxIter = 10)\n",
    "train_data.printSchema()\n",
    "lr_Model = lr.fit(train_data)\n",
    "pred = lr_Model.transform(test_data)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval.evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc = DecisionTreeClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_pred = dtc_model.transform(test_data)\n",
    "dtc_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval2 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval2.evaluate(dtc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = RandomForestClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\n",
    "rfc_model = rfc.fit(train_data)\n",
    "rfc_pred = rfc_model.transform(test_data)\n",
    "rfc_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval3 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')\n",
    "my_eval3.evaluate(rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "gbc = GBTClassifier\n",
    "gbc = GBTClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\n",
    "gbc_model = gbc.fit(train_data)\n",
    "gbc_pred = gbc_model.transform(test_data)\n",
    "gbc_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval4 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')\n",
    "my_eval4.evaluate(gbc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***\n",
    "### Random forest based prediction model works best. Hence, training Random Forest model on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the test dataset\n",
    "test=spark.read.csv(\"/FileStore/tables/test.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in test.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing nulls in gender\n",
    "Gender_counts = test.groupBy(['Gender']).count().alias('counts')\n",
    "Gender_counts.sort(col(\"count\").desc()).show()\n",
    "Gender_mode=Gender_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_Gender = Gender_counts.filter(Gender_counts['count']==Gender_mode)\n",
    "Gender_mode = temp_Gender.select(['Gender']).collect()[0][0]\n",
    "test=test.na.fill(Gender_mode,subset=['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null in self employed\n",
    "emp_counts = test.groupBy(['Self_Employed']).count().alias('counts')\n",
    "emp_counts.sort(col(\"count\").desc()).show()\n",
    "emp_mode=emp_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_emp = emp_counts.filter(emp_counts['count']==emp_mode)\n",
    "emp_mode = temp_emp.select(['Self_Employed']).collect()[0][0]\n",
    "test=test.na.fill(emp_mode,subset=['Self_Employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null in dependents \n",
    "Dep_counts = test.groupBy(['Dependents']).count().alias('counts')\n",
    "Dep_counts.sort(col(\"count\").desc()).show()\n",
    "Dep_mode=Dep_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_dep = Dep_counts.filter(Dep_counts['count']==Dep_mode)\n",
    "Dep_mode = temp_dep.select(['Dependents']).collect()[0][0]\n",
    "test=test.na.fill(Dep_mode,subset=['Dependents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null in credit history\n",
    "ch_counts = test.groupBy(['Credit_History']).count().alias('counts')\n",
    "ch_counts.sort(col(\"count\").desc()).show()\n",
    "ch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\n",
    "ch_mode = temp_ch.select(['Credit_History']).collect()[0][0]\n",
    "test=test.na.fill(ch_mode,subset=['Credit_History'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing nulls in Loan amount \n",
    "from pyspark.sql.functions import mean, md5\n",
    "mean_val= test.select(mean(test['LoanAmount'])).collect()\n",
    "mean_la=mean_val[0][0]\n",
    "test=test.na.fill(mean_la,subset=['LoanAmount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null in loan amount term\n",
    "ch_counts = test.groupBy(['Loan_Amount_Term']).count().alias('counts')\n",
    "ch_counts.sort(col(\"count\").desc()).show()\n",
    "ch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "temp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\n",
    "ch_mode = temp_ch.select(['Loan_Amount_Term']).collect()[0][0]\n",
    "test=test.na.fill(ch_mode,subset=['Loan_Amount_Term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_totalincome = test.withColumn('total_income', test['ApplicantIncome']+test['CoapplicantIncome'])\n",
    "test_with_totalincome.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_ratio = test_with_totalincome.withColumn('ratio', test_with_totalincome['total_income']/test_with_totalincome['LoanAmount'])\n",
    "test_with_ratio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final dataset after removing nulls\n",
    "test_final = test_with_ratio.select('Gender',\n",
    " 'Married',\n",
    " 'Dependents',\n",
    " 'Education',\n",
    " 'Self_Employed',\n",
    " 'ApplicantIncome',\n",
    " 'CoapplicantIncome',\n",
    " 'LoanAmount',\n",
    " 'Loan_Amount_Term',\n",
    " 'Credit_History',\n",
    " 'Property_Area',\n",
    "'total_income','ratio')\n",
    "test_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding features of test dataset\n",
    "gen_indexed = gen_model.transform(test_final)\n",
    "test_final1= gen_encoder.transform(gen_indexed)\n",
    "mar_indexed = mar_model.transform(test_final1)\n",
    "test_final2 = mar_encoder.transform(mar_indexed)\n",
    "dep_indexed = dep_model.transform(test_final2)\n",
    "test_final3 = dep_encoder.transform(dep_indexed)\n",
    "edu_indexed = edu_model.transform(test_final3)\n",
    "test_final4 = edu_encoder.transform(edu_indexed)\n",
    "emp_indexed = emp_model.transform(test_final4)\n",
    "test_final5 = emp_encoder.transform(emp_indexed)\n",
    "area_indexed = area_model.transform(test_final5)\n",
    "test_final6 = area_encoder.transform(area_indexed)\n",
    "test_final6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assembling columns and creating feature column for test dataset\n",
    "test_final7=assembler.transform(test_final6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building model on entire training dataset(without splitting)\n",
    "#Random forest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = RandomForestClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\n",
    "rfc_model = rfc.fit(new_final)\n",
    "rfc_pred = rfc_model.transform(test_final7)\n",
    "rfc_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final predictions on test data\n",
    "predictions_dataset = rfc_pred.select('features','rawPrediction','probability','prediction')\n",
    "predictions_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=rfc_pred.filter(rfc_pred['prediction']==\"1\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select('summary','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','total_income','ratio').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "model with updates",
  "notebookId": 475508854023478
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
