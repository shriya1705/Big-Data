{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Project').getOrCreate()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["df = spark.read.csv('/FileStore/tables/train.csv', inferSchema=True, header = True)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.functions import isnan, when, count, col\n\ndf.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#So the columns containing missing values are: Gender, Married, Dependents, Self-Employed, LoanAmount, Loan_Amount_Term and Credit _History\n#There are various ways of imputing missing values: here we will replace missing values with mean for continuous values and mode for categorical. In the later part, we will run boosting and random forest without imputing the missing values as they have capacity to treat it themselves and then test the accuracy."],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql.functions import mean"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["mean_value = df.select(mean(df['LoanAmount'])).collect()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["mean_loan_amount = mean_value[0][0]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["df = df.na.fill(mean_loan_amount, subset = ['LoanAmount'])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["df.createOrReplaceTempView(\"loan\")"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["spark.sql(\"SELECT * FROM loan\").show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["results = spark.sql(\"select LoanAmount from loan where LoanAmount is not null\")\nresults.collect()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["result_array = results.rdd.map(lambda row : row.LoanAmount).collect()\nresult_array"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["%matplotlib inline"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.boxplot(result_array)\nax.set_title('Variance in Loan Amount')"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(fig)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["results_lat = spark.sql(\"select Loan_Amount_Term from loan where Loan_Amount_Term is not null\")\nresult_array_lat = results_lat.rdd.map(lambda row : row.Loan_Amount_Term).collect()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.boxplot(result_array_lat)\nax.set_title('Variance in Loan Amount Term')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["display(fig)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["results_ai = spark.sql(\"select ApplicantIncome from loan where ApplicantIncome is not null\")\nresult_array_ai = results_ai.rdd.map(lambda row : row.ApplicantIncome).collect()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.boxplot(result_array_ai)\nax.set_title('Variance in Applicant Income')"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["display(fig)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["results_cai = spark.sql(\"select CoapplicantIncome from loan where CoapplicantIncome is not null\")\nresult_array_cai = results_cai.rdd.map(lambda row : row.CoapplicantIncome).collect()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax=fig.add_subplot(111, projection = '3d')\n\nax.scatter( result_array, result_array_ai, result_array_cai , c='r', marker = 'o')\n\nax.set_xlabel('LoanAmount')\nax.set_ylabel('ApplicantIncome')\nax.set_zlabel('CoapplicantIncome')\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["display(fig)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["results_gender = spark.sql(\"select Gender from loan where Gender is not null\")\nresult_array_gender = results_gender.rdd.map(lambda row : row.Gender).collect()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["results_ls = spark.sql(\"select Loan_Status from loan where Loan_Status  is not null\")\nresult_array_ls = results_ls.rdd.map(lambda row : row.Loan_Status ).collect()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["results_comb = spark.sql(\"select ApplicantIncome, Gender, Loan_Status from loan where ApplicantIncome is not null and Gender is not null and  Loan_Status is not null\")"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["results_comb.registerTempTable(\"combo_table\")\ndisplay(sqlContext.sql(\"select * from combo_table\"))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["%sql select * from combo_table"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":38}],"metadata":{"name":"Project_Part1","notebookId":4105248093929968},"nbformat":4,"nbformat_minor":0}
